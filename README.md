# PrISM : Annotating Precision for Integrative Structure Models
PrISM is a package for visualizing regions of high and low precision in ensembles of integrative models. It uses autoencoders, a class of deep-learning networks, to annotate bead-wise precision scalably for ensembles of large macromolecular assemblies.

## Installation
PrISM requires python packages that can be installed with the following types of commands:

```
pip3 install --user -r install_requires.txt 
or 
pip install -r install_requires.txt 
```

## Running PriSM 

### Inputs
There are three ways to run PrISM, based on the inputs at hand. 

1. `NPZ`: Runs PrISM directly on the output of the IMP analysis pipeline, after running `imp-sampcon`, the module to test sampling exhaustiveness and cluster sampled models generated using [IMP](http://integrativemodeling.org). For each output cluster, the superposed bead coordinates are stored in a `.npz` file (e.g., `cluster.0.superposed.npz` for cluster 0), which is passed as input to PriSM. 

2. `RMF`: Runs PrISM on a directory with a set of superposed integrative models in RMF format. 
Note that PrISM requires superposed models and does not perform the structural superposition before calculating precision. 
The RMF format is commonly used to store integrative models generated by [IMP](http://integrativemodeling.org).

3. `PDB`: Runs PrISM on a directory with a set of superposed integrative models in PDB format. 
Note that PrISM requires superposed models and does not perform the structural superposition before calculating precision. 
The PDB format is commonly used to store atomistic integrative models. 

### Run command

Run PrISM like this:

```
python run_prism.py 7CEI/ 7CEI_img
```

where the first argument is the directory containing a set of RMF files which we want to analyze and the second is the base directory for the output file. The script stores output in the desired output directory (7CEI_img here) in the file `all_models_coordinates.npz`.

```buildoutcfg
python generate_input/generate_distance_vectors.py --input <input-dir-npz-file> --output <output_dir>
```

# Training Models
Currently training the following models are supported. 
* VAE with BatchNorm of fixed size reconstruction of 64 X 64
* Variable backbone VAE - Can use any of the torchvision models (VGG, ResNet, etc)

The training can be triggered by running the following command
```buildoutcfg
python train.py --config test_config.yml
```
[Sample test_config.yml]()
```buildoutcfg
model_architecture: VAE_bn
lr: 1e-3
loss: kl_divergence
input_path: test_data
output_path: runs
batch_size: 4
epochs: 100
seed: 1
log-interval: 10
```


